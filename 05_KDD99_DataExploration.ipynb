{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GMV](https://upload.wikimedia.org/wikipedia/en/3/31/GMV_logo_small_gif.gif) \n",
    "![Apache Spark](http://spark.apache.org/images/spark-logo.png)\n",
    "\n",
    "# Intrusion Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract \n",
    "--------\n",
    "\n",
    "Security and privacy of a system is compromised, when an intrusion happens. Intrusion Detection System (IDS) plays vital role in network security as it detects various types of attacks in network. So here, we are going to propose Intrusion Detection System using machine learning algorithms. The proposed system will be done by conducting some experiments using [NSL-KDD Cup’99](http://nsl.cs.unb.ca/NSL-KDD/) dataset which is improved version of [KDD Cup’99 data set](http://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining Process\n",
    "------------------- \n",
    "The [Cross Industry Standard Process for Data Mining](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining) introduced a process model for data mining in 2000 that has become widely adopted.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining\"> \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/479px-CRISP-DM_Process_Diagram.png\" title=\"Cross Industry Standard Process for Data Mining\" alt=\"CRISP-DM_Process_Diagram\"/></a>\n",
    "\n",
    "\n",
    "\n",
    "The model emphasizes the ***iterative*** nature of the data mining process, distinguishing several different stages that are regularly revisited in the course of developing and deploying data-driven solutions to business problems\n",
    "* Business understanding\n",
    "* Data understanding\n",
    "* Data preparation\n",
    "* Modeling\n",
    "* Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowadays the cyber security threats are rising and putting in risk a great number of organizations. Any organization could be a target for the attackers that produce huge damages into it.\n",
    "\n",
    "For these reasons it's necessary to provide a system that help to detect intruders in a network. This intrusion detection system should be non-invasive to other systems to provide a quick deployment and to get results a soon as possible. \n",
    "\n",
    "It's also important to balance the number of false positives (that increase the maintenance of the system) with the number of false negatives (that would allow to intruders achieve their objectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KDD Cup'99 data set** used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between **``bad'' connections**, called intrusions or attacks, and **``good'' normal connections**. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment.\n",
    "\n",
    "**NSL-KDD** is a data set suggested to solve some of the inherent problems of the KDD'99 data set. Although, this new version of the KDD data set still suffers from some of the problems and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable\n",
    "\n",
    "A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol.  Each connection is labeled as either normal, or as an attack, with exactly one specific attack type.  Each connection record consists of about 100 bytes.\n",
    "\n",
    "Attacks fall into four main categories:\n",
    "\n",
    "* DOS: denial-of-service, e.g. syn flood;\n",
    "* R2L: unauthorized access from a remote machine, e.g. guessing password;\n",
    "* U2R:  unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;\n",
    "* probing: surveillance and other probing, e.g., port scanning.\n",
    "\n",
    "It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data.  This makes the task more realistic.  Some intrusion experts believe that most novel attacks are variants of known attacks and the \"signature\" of known attacks can be sufficient to catch novel variants.  The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only. \n",
    "\n",
    "### Derived Features ###\n",
    "\n",
    "Higher-level features had been defined that help in distinguishing *normal* connections from *attacks*.  There are several categories of derived features.\n",
    "\n",
    "**Intrinsic attributes**\n",
    "\n",
    "These attributes are extracted from the headers' area of the network packets.\n",
    "\n",
    "Col|Feature name  | description |\ttype\n",
    "---|--------------|-------------|------------\n",
    "1  |duration \t  |length (number of seconds) of the connection |continuous\n",
    "2  |protocol_type |type of the protocol, e.g. tcp, udp, etc. |discrete\n",
    "3  |service \t  |network service on the destination, e.g., http, telnet, etc. |discrete\n",
    "4  |flag \t      |normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR \t|discrete \n",
    "5  |src_bytes \t  |number of data bytes from source to destination \t|continuous\n",
    "6  |dst_bytes \t  |number of data bytes from destination to source \t|continuous\n",
    "7  |land \t      |1 if connection is from/to the same host/port; 0 otherwise \t|discrete\n",
    "8  |wrong_fragment|sum of bad checksum packets in a connection \t|continuous\n",
    "9  |urgent \t      |number of urgent packets. Urgent packets are packets with the urgent bit activated \t|continuous\n",
    "\n",
    "\n",
    "\n",
    "**Content attributes** \n",
    "\n",
    "These attributes are extracted from the contents area of the network packets based on expert person knowledge.\n",
    "\n",
    "Col|Feature name\t      |description \t|type\n",
    "---|----------------------|-------------|-----\n",
    "10 |hot \t              |sum of hot actions in a connection such as: entering a system direc- tory, creating programs and executing programs\t|continuous\n",
    "11 |num_failed_logins \t  |number of failed login attempts \t|continuous\n",
    "12 |logged_in \t          |1 if successfully logged in; 0 otherwise \t|discrete\n",
    "13 |num_compromised \t  |number of \"compromised\" conditions \t|continuous\n",
    "14 |root_shell \t          |1 if root shell is obtained; 0 otherwise \t|discrete\n",
    "15 |su_attempted \t      |1 if \"su root\" command attempted; 0 otherwise \t|discrete\n",
    "16 |num_root \t          |number of \"root'\" accesses \t|continuous\n",
    "17 |num_file_creations \t  |number of file creation operations \t|continuous\n",
    "18 |num_shells \t          |number of shell prompts \t|continuous\n",
    "19 |num_access_files \t  |number of operations on access control files \t|continuous\n",
    "20 |num_outbound_cmds\t  |number of outbound commands in an ftp session \t|continuous\n",
    "21 |is_hot_login \t      |1 if the login belongs to the \"hot\" list; 0 otherwise \t|discrete\n",
    "22 |is_guest_login \t      |1 if the login is a \"guest\" login; 0 otherwise \t|discrete\n",
    "\n",
    "**Traffic attributes**\n",
    "\n",
    "These attributes are calculated taking into account the previous connections. 9+10 attributes are divided into two groups: (1) time traffic features (2) machine traffic features. The difference between one group and the other is the mode to select the previous connections.\n",
    "\n",
    "\n",
    "*Time traffic attributes*\n",
    "\n",
    "To calculate these attributes we considered the connections that occurred in the past 2 seconds.\n",
    "\n",
    "Col|Feature name\t      |description \t|type\n",
    "---|----------------------|-------------|-----\n",
    "23 |count \t              |sum of connections to the same destination IP address |continuous\n",
    "24 |srv_count \t          |sum of connections to the same destination port number |continuous\n",
    "25 |serror_rate \t      |the percentage of connections that have activated the flag (4) s0, s1, s2 or s3, among the connections aggregated in count (23)|continuous\n",
    "26 |srv_serror_rate \t  |the percentage of connections that have activated the flag (4) s0, s1, s2 or s3, among the connections aggregated in srv_count (24)|continuous\n",
    "27 |rerror_rate \t      |the percentage of connections that have activated the flag (4) REJ, among the connections aggregated in count (23)|continuous\n",
    "29 |same_srv_rate \t      |the percentage of connections that have activated the flag (4) REJ, among the connections aggregated in srv_count (24)|continuous\n",
    "28 |srv_rerror_rate \t  |the percentage of connections that were to the same service, among the connections aggregated in count (23)|continuous\n",
    "30 |diff_srv_rate \t      |the percentage of connections that were to different services, among the connections aggregated in count (23)|continuous\n",
    "31 |srv_diff_host_rate \t  |the percentage of connections that were to different destination ma- chines among the connections aggregated in srv_count (24)|continuous\n",
    "\n",
    "*Machine traffic attributes*\n",
    "\n",
    "To calculate these attributes we took into account the previous 100 connections.\n",
    "\n",
    "Col|Feature name\t      |description \t|type\n",
    "---|----------------------|-------------|-----\n",
    "32 |dst_host_count        |sum of connections to the same destination IP address   |continuous\n",
    "33 |dst_host_srv_count    |sum of connections to the same destination port number  |continuous\n",
    "34 |dst_host_same_srv_rate|the percentage of connections that were to the same service, among the connections aggregated in dst_host_count (32)|continuous \n",
    "35 |dst_host_diff_srv_rate|the percentage of connections that were to different services, among the connections aggregated in dst_host_count (32)|continuous \n",
    "36 |dst_host_same_src_port_rate|the percentage of connections that were to the same source port, among the connections aggregated in dst_host_srv_count (33)|continuous \n",
    "37 |dst_host_srv_diff_host_rate|the percentage of connections that were to different destination ma- chines, among the connections aggregated in dst_host_srv_count (33)|continuous \n",
    "38 |dst_host_serror_rate  |the percentage of connections that have activated the flag (4) s0, s1, s2 or s3, among the connections aggregated in dst_host_count (32)|continuous\n",
    "39 |dst_host_srv_serror_rate|the percent of connections that have activated the flag (4) s0, s1, s2 or s3, among the connections aggregated in dst_host_srv_count (33)|continuous \n",
    "40 |dst_host_rerror_rate  |the percentage of connections that have activated the flag (4) REJ, among the connections aggregated in dst_host_count (32)|continuous\n",
    "41 |dst_host_srv_rerror_rate|the percentage of connections that have activated the flag (4) REJ, among the connections aggregated in dst_host_srv_count (33)|continuous \n",
    "\n",
    "\n",
    "\n",
    "**Class attribute**\n",
    "\n",
    "The 42nd attribute is the ***class*** attribute, it indicates which type of connections is each instance: normal or which attack. The values it can take are the following: *anomaly, dict, dict_simple, eject, eject-fail, ffb, ffb_clear, format, format_clear, format-fail, ftp-write, guest, imap, land, load_clear, loadmodule, multihop, perl_clear, perlmagic, phf, rootkit, spy, syslog, teardrop, warez, warezclient, warezmaster, pod, back, ip- sweep, neptune, nmap, portsweep, satan, smurf and normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"SecurityDataScience\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn palette setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font= 'serif', font_scale=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFileConn = sc.textFile('./data/KDD/KDDTrain+.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFileConn.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFileConn.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the schema\n",
    "\n",
    "#we define the name of the columns\n",
    "columnNames = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "              \"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
    "              \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "              \"num_access_files\",\"num_outbound_cmds\",\"is_hot_login\",\"is_guest_login\",\"count\",\n",
    "              \"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"same_srv_rate\",\n",
    "              \"srv_rerror_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\n",
    "              \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n",
    "              \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "              \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
    "              \"attack\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fields initialitation all for FloatType\n",
    "connFields = [StructField(colName, FloatType(), True) for colName in columnNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we proceed to modify the respective fields so that they reflect the correct data type:\n",
    "connFields[1].dataType = StringType()\n",
    "connFields[2].dataType = StringType()\n",
    "connFields[3].dataType = StringType()\n",
    "connFields[6].dataType = StringType()\n",
    "connFields[11].dataType = StringType()\n",
    "connFields[13].dataType = StringType()\n",
    "connFields[14].dataType = StringType()\n",
    "connFields[20].dataType = StringType()\n",
    "connFields[21].dataType = StringType()\n",
    "connFields[41].dataType = StringType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can construct our schema, which we will use later below for building the data frame\n",
    "connSchema = StructType(connFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the file\n",
    "def parseReg(p):\n",
    "    return ( float(p[0])\n",
    "            ,p[1], p[2], p[3] \n",
    "            ,float(p[4])\n",
    "            ,float(p[5])\n",
    "            ,p[6]\n",
    "            ,float(p[7])\n",
    "            ,float(p[8])\n",
    "            ,float(p[9])\n",
    "            ,float(p[10])\n",
    "            ,p[11]\n",
    "            ,float(p[12])\n",
    "            ,p[13], p[14]\n",
    "            ,float(p[15])\n",
    "            ,float(p[16])\n",
    "            ,float(p[17])\n",
    "            ,float(p[18])\n",
    "            ,float(p[19])\n",
    "            ,p[20], p[21]\n",
    "            ,float(p[22])\n",
    "            ,float(p[23])\n",
    "            ,float(p[24])\n",
    "            ,float(p[25])\n",
    "            ,float(p[26])\n",
    "            ,float(p[27])\n",
    "            ,float(p[28])\n",
    "            ,float(p[29])\n",
    "            ,float(p[30])\n",
    "            ,float(p[31])\n",
    "            ,float(p[32])\n",
    "            ,float(p[33])\n",
    "            ,float(p[34])\n",
    "            ,float(p[35])\n",
    "            ,float(p[36])\n",
    "            ,float(p[37])\n",
    "            ,float(p[38])\n",
    "            ,float(p[39])\n",
    "            ,float(p[40])\n",
    "            ,p[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connParsedFile = (textFileConn.map(lambda line: line.split(','))\n",
    "                              .map(parseReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We are now ready to build our data frame, using the connParsedFile RDD computed above and the schema \n",
    "# variable already calculated:\n",
    "conn = sqlContext.createDataFrame(connParsedFile, connSchema)\n",
    "conn.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the schema, and register the DataFrame as a table.\n",
    "conn.registerTempTable(\"connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageOf(df, colName=''):\n",
    "    \"\"\"Calculate the percentage of each categorical value of colName from de Spark DataFrame df\n",
    "    \n",
    "    Keyword arguments:\n",
    "    df -- the DataFrame\n",
    "    colName -- the name of the column\n",
    "    \"\"\"\n",
    "    rows = df.groupBy(colName).count().collect()\n",
    "    total = 0\n",
    "    for r in rows:\n",
    "        total += r.asDict()[\"count\"]\n",
    "    dictResult = {r.asDict()[colName]: 1.0*r.asDict()[\"count\"]/total for r in rows}\n",
    "    return sorted(dictResult.items(), key=lambda x: x[1], reverse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOf(df, colName=''):\n",
    "    \"\"\"Calculate the number of each categorical value of colName from de Spark DataFrame df\n",
    "    \n",
    "    Keyword arguments:\n",
    "    df -- the DataFrame\n",
    "    colName -- the name of the column\n",
    "    \"\"\"\n",
    "    rows = df.groupBy(colName).count().collect()\n",
    "    dictResult = {r.asDict()[colName]: r.asDict()['count'] for r in rows}\n",
    "    return sorted(dictResult.items(), key=lambda x: x[1], reverse= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('duration').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data set is big --> Getting only a sample of the data set for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample = conn.sample(True, 0.05).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.duration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample.duration, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skew distribution -> log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(connSample.duration+1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(connSample.duration+1), bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's inspect how many values are equal to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numbers of 0's in duration feature: \", len(connSample.duration[connSample.duration == 0]))\n",
    "print(\"The percentage of 0's in duration feature:\", 100.0*len(connSample.duration[connSample.duration == 0])/len(connSample.duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting the distribution without 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(connSample.duration[connSample.duration>0]+1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(connSample.duration[connSample.duration > 0]+1), bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** protocol_type\n",
    "* **description:** type of the protocol, e.g. tcp, udp, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('protocol_type').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the percentage of the values\n",
    "percentageOf(conn, 'protocol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics with the sample data\n",
    "connSample.protocol_type.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='protocol_type', data = connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Percentages of protocol_type: \")\n",
    "print(1.0*connSample.protocol_type.value_counts()/len(connSample.protocol_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** service\n",
    "* **description:** network service on the destination, e.g., http, telnet, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('service').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get all different values\n",
    "conn.freqItems(['service']).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get the percentage of the values\n",
    "percentageOf(conn, 'service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.service.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='service', data=connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font= 'serif', font_scale= 0.65)\n",
    "sns.countplot(y='service', data=connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of service's value:\")\n",
    "print(1.0*connSample.service.value_counts()/len(connSample.service))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** flag\n",
    "* **description:** normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('flag').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all different values\n",
    "conn.freqItems(['flag']).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the percentage of the values\n",
    "percentageOf(conn, 'flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get stats with the Sample\n",
    "connSample.flag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='flag', data=connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of flag's value:\")\n",
    "print(1.0*connSample.flag.value_counts()/len(connSample.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** src_bytes\n",
    "* **description:** number of data bytes from source to destination\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('src_bytes').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats with the sample\n",
    "connSample.src_bytes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample.src_bytes, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skew distribution -> log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(connSample.src_bytes+1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(connSample.src_bytes+1), bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** dst_bytes\n",
    "* **description:** number of data bytes from destination to source\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('dst_bytes').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transformation with all data\n",
    "conn.select(log(conn['dst_bytes']+1)).describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics with sample data\n",
    "np.log(connSample.dst_bytes+1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(connSample.dst_bytes+1), bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** land\n",
    "* **description:** 1 if connection is from/to the same host/port; 0 otherwise\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('land').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOf(conn, 'land')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.land.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='land', data=connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.land.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of lands's value:\")\n",
    "print(1.0*connSample.land.value_counts()/len(connSample.land))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** wrong_fragment\t\n",
    "* **description:** sum of bad checksum packets in a connection\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('wrong_fragment').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the percentage of the values\n",
    "numberOf(conn, 'wrong_fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stat from sample data\n",
    "connSample.wrong_fragment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x= 'wrong_fragment', data= connSample, palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.wrong_fragment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of wrong_fragment's value:\")\n",
    "print(1.0*connSample.wrong_fragment.value_counts()/len(connSample.wrong_fragment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** urgent\t\n",
    "* **description:** number of urgent packets. Urgent packets are packets with the urgent bit activated\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics with all data\n",
    "conn.describe('urgent').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the percentage of the values\n",
    "numberOf(conn, 'urgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.urgent.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.urgent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of urgent's value:\")\n",
    "print(1.0*connSample.urgent.value_counts()/len(connSample.urgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'urgent', data = connSample, palette=\"Paired\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions: Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant conclusions of univariante Analysis are:\n",
    "* **duration:** is highly right-skewed. In fact the 92% of the values are 0's. The log transformation without 0's seems to have a bimodal distribution\n",
    "* **connection_type:** has most of the instances with the values *tcp* (81%)\n",
    "* **service:** only two values (*http* and *private*) of 70 concentrate the 50% of the instances\n",
    "* **flag:** only three values (*SF*, *S0* and *REJ*) of 11 concentrate the 95% of the instances\n",
    "* **src_bytes:** is right-skewed. The log transformation seems to have a bimodal distribution\n",
    "* **dst_bytes:** is right-skewed. The log transformation seems to have a bimodal distribution\n",
    "* **land:** actually is a discrete feature with two values: 0 and 1. The 99,98% of the instances have the value 0\n",
    "* **wrong_fragment:** is a continuous variable with only three values: 0, 1 and 3. The 99.13% of the instances have the value 0\n",
    "* **urgent:** is a continuous variable with only four values: 0, 1, 2 and 3. The 99.99% of the instances have the value 0\n",
    "\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs protocol_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** protocol_type\n",
    "* **description:** type of the protocol, e.g. tcp, udp, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'protocol_type', y='duration', data = connSample, palette= 'Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample['duration_log'] = np.log(connSample.duration+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'protocol_type', y = 'duration_log', data = connSample, palette= 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting the distribution with duration_log more than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x= 'protocol_type', y= 'duration_log'\n",
    "            , data = connSample[connSample.duration_log > 0]\n",
    "            , palette = 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting the distribution with duration_log == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x='protocol_type' \n",
    "              , data = connSample[connSample.duration_log == 0]\n",
    "              , palette = 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs protocol_type analysis\n",
    "* Regardless the *protocol_type* feature most of the values of *duration* features are 0's\n",
    "* When the value of *protocol_type* is *'icmp'* all the values of *duration* features is 0\n",
    "* After the log(x+1) transformation of *protocol_type* and removing the 0's values, the distributions of *duration* is very different between *'tcp'* and *'udp'* \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Make the *duration* vs *service* analysis\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample[connSample.duration_log>0].boxplot('duration_log', \n",
    "                                              by='service', \n",
    "                                              rot = 45, \n",
    "                                              figsize = (15, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)\n",
    "sns.countplot(y='service', data = connSample[connSample.duration_log == 0], palette= 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** flag\n",
    "* **description:** normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample[connSample.duration > 0].boxplot('duration_log', by='flag');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting the distribution with duration_log == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'flag', data = connSample[connSample.duration_log == 0], palette= 'Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentages of flag's value:\")\n",
    "print(1.0*connSample[connSample.duration_log == 0].flag.value_counts()/len(connSample[connSample.duration_log == 0].flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs flag analysis\n",
    "* Regardless the *flag* feature most of the values of *duration* features are 0's\n",
    "* After the log(x+1) transformation of *flag* and removing the 0's values, the distributions of *duration* is very different in *'RSTR'* and *'RSTOS0'* categories \n",
    "* If duration_log is 0, only three values (*SF*, *S0* and *REJ*) of 11 concentrate the 96% of the instances\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs src_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** src_bytes\n",
    "* **description:** number of data bytes from source to destination\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample['src_bytes_log'] = np.log(connSample.src_bytes+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with duration > 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = sns.color_palette()[2]\n",
    "sns.jointplot(\"duration_log\", \"src_bytes_log\", data=connSample[connSample.duration>0], \n",
    "              kind=\"reg\", color = color, size=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with kde (Kernel density estimation)\n",
    "color = sns.color_palette()[3]\n",
    "sns.jointplot(\"duration_log\", \"src_bytes_log\", \n",
    "              data=connSample[connSample.duration>0], \n",
    "              kind=\"kde\", color = color, size=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with duration == 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample[connSample.duration_log == 0].src_bytes_log, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with src_bytes_log == 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample[connSample.src_bytes_log == 0].duration_log, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs src_bytes analysis\n",
    "The analysis was splited in three cases:\n",
    "* Case 1: *duration_log* and *src_bytes_logs* are greater than 0:\n",
    "    - There are not strong correlation between *duration_log* and *src_bytes_log*\n",
    "    - On the other hand, it seems there are some clusters between both variables\n",
    "* Case 2: *duration_log* is equal to 0:\n",
    "    - It seems *src_bytes* has a multimodal distribution\n",
    "* Case 3: *src_bytes_log* is equal to 0:\n",
    "    - Most of the values of *duration_log* is equal to 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs dst_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** dst_bytes\n",
    "* **description:** number of data bytes from destination to source\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample['dst_bytes_log'] = np.log(connSample.dst_bytes+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\"duration_log\", \"dst_bytes_log\", \n",
    "              data= connSample[connSample.duration>0], \n",
    "              kind=\"reg\", size=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with kde (Kernel density estimation)\n",
    "color = sns.color_palette()[2]\n",
    "sns.jointplot(\"duration_log\", \"dst_bytes_log\", \n",
    "              data= connSample[connSample.duration>0], \n",
    "              color = color, kind=\"kde\", size=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with duration == 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample[connSample.duration_log == 0].dst_bytes_log, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with dst_bytes_log == 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(connSample[connSample.dst_bytes_log == 0].duration_log, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs dst_bytes analysis\n",
    "The analysis was splited in three cases:\n",
    "* Case 1: *duration_log* and *dst_bytes_logs* are greater than 0:\n",
    "    - There are not strong correlation between *duration_log* and *dst_bytes_log*\n",
    "    - On the other hand, it seems there are some clusters between both variables\n",
    "* Case 2: *duration_log* is equal to 0:\n",
    "    - It seems *dst_bytes* has a bimodal distribution\n",
    "* Case 3: *dst_bytes_log* is equal to 0:\n",
    "    - Most of the values of *duration_log* is equal to 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs land"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** land\n",
    "* **description:** 1 if connection is from/to the same host/port; 0 otherwise\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"land\", y = \"duration_log\", data= connSample, palette= 'Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.pivot_table(\"duration_log\",\"land\", aggfunc=np.average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with duration > 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"land\", y = \"duration_log\", \n",
    "            data= connSample[connSample.duration > 0], \n",
    "            palette= 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Conclusions duration vs land analysis\n",
    "* If *duration_log* is greater than 0 then we have only values with *land* == 0 and its distribution is right-skewed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration vs wrong_fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** wrong_fragment\t\n",
    "* **description:** sum of bad checksum packets in a connection\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x= 'wrong_fragment', y= 'duration_log', \n",
    "           data = connSample, \n",
    "           palette = 'Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.pivot_table(\"duration_log\",\"wrong_fragment\", aggfunc=np.average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting with duration > 0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x= 'wrong_fragment', y= 'duration_log', \n",
    "           data = connSample[connSample.duration_log > 0], \n",
    "           palette = 'Paired');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs wrong_fragment\n",
    "\n",
    "* If *duration_log* is greater than 0 then we have only values with *wrong_fragment* == 0 and its distribution is right-skewed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercicie 2: duration vs urgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** duration\n",
    "* **description:** length (number of seconds) of the connection\n",
    "* **type:** continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** urgent\t\n",
    "* **description:** number of urgent packets. Urgent packets are packets with the urgent bit activated\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions duration vs urgent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protocol_type vs service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** protocol_type\n",
    "* **description:** type of the protocol, e.g. tcp, udp, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** service\n",
    "* **description:** network service on the destination, e.g., http, telnet, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.pivot_table(\"attack\", \"service\",\"protocol_type\", aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font= 'serif', font_scale=0.65, rc={\"figure.figsize\": (3, 10)})\n",
    "sns.heatmap(connSample.pivot_table(\"attack\", \"service\",\"protocol_type\", aggfunc=len), \n",
    "            square= False,\n",
    "            annot=True, annot_kws={\"size\": 7}, fmt=\".0f\", linewidths= .5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions protocol_type vs service analysis\n",
    "* Except two general services (*'other'* and *'private'*) all the *services* categories belong to a *protocol_type* category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protocol_type vs flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** protocol_type\n",
    "* **description:** type of the protocol, e.g. tcp, udp, etc.\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** flag\n",
    "* **description:** normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font= 'serif', font_scale=0.65, rc={\"figure.figsize\": (3, 6)})\n",
    "sns.heatmap(connSample.pivot_table(\"attack\", \"flag\",\"protocol_type\", aggfunc=len), \n",
    "            annot=True, fmt=\".0f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions protocol_type vs flag analysis\n",
    "* All *flag* categories beleng only to *'tcp'* *protocol_type* except *'SF'* flag that belongs to the three *protocol_type*s\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: protocol_type vs src_bytes\n",
    "Make the *protocol_type* vs *src_bytes* analysis\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: protocol_type vs dst_bytes\n",
    "Make the *protocol_type* vs *dst_bytes* analysis\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### src_bytes & dst_bytes & wrong_fragmnet & urgent vs class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** urgent\t\n",
    "* **description:** number of urgent packets. Urgent packets are packets with the urgent bit activated\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** src_bytes\n",
    "* **description:** number of data bytes from source to destination\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** dst_bytes\n",
    "* **description:** number of data bytes from destination to source\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** wrong_fragment\t\n",
    "* **description:** sum of bad checksum packets in a connection\n",
    "* **type:** continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **name:** attack\t\n",
    "* **description:** is the label attribute and indicates which type of connections is each instance: normal or which attack. The values it can take are the following: *anomaly, dict, dict_simple, eject, eject-fail, ffb, ffb_clear, format, format_clear, format-fail, ftp-write, guest, imap, land, load_clear, loadmodule, multihop, perl_clear, perlmagic, phf, rootkit, spy, syslog, teardrop, warez, warezclient, warezmaster, pod, back, ip- sweep, neptune, nmap, portsweep, satan, smurf and normal*\n",
    "* **type:** discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of \"is_attack\" attribute to differentiate the normal connections vs attack connections\n",
    "connSample[\"is_attack\"] = connSample[\"attack\"].map(lambda x: int(x != \"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(connSample, \n",
    "             vars=['src_bytes_log','dst_bytes_log','wrong_fragment','urgent'], \n",
    "             hue='is_attack');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
