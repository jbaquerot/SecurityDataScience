{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GMV](https://www.gmv.com/export/system/modules/com.gmv.teresa.site/resources/theme/img/logo_gmv.svg)  ![Apache Spark](http://spark.apache.org/images/spark-logo.png)\n",
    "\n",
    "# KDD99 Supervised Learning II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"SecurityDataScience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intrinsic attributes**\n",
    "\n",
    "These attributes are extracted from the headers' area of the network packets.\n",
    "\n",
    "Col|Feature name  | description |\ttype\n",
    "---|--------------|-------------|------------\n",
    "1  |duration \t  |length (number of seconds) of the connection |continuous\n",
    "2  |protocol_type |type of the protocol, e.g. tcp, udp, etc. |discrete\n",
    "3  |service \t  |network service on the destination, e.g., http, telnet, etc. |discrete\n",
    "4  |flag \t      |normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR \t|discrete \n",
    "5  |src_bytes \t  |number of data bytes from source to destination \t|continuous\n",
    "6  |dst_bytes \t  |number of data bytes from destination to source \t|continuous\n",
    "7  |land \t      |1 if connection is from/to the same host/port; 0 otherwise \t|discrete\n",
    "8  |wrong_fragment|sum of bad checksum packets in a connection \t|continuous\n",
    "9  |urgent \t      |number of urgent packets. Urgent packets are packets with the urgent bit activated \t|continuous\n",
    "\n",
    "\n",
    "**Class attribute**\n",
    "\n",
    "The 42nd attribute is the ***class_attack*** attribute, it indicates which type of connections is each instance: normal or which attack. The values it can take are the following: *anomaly, dict, dict_simple, eject, eject-fail, ffb, ffb_clear, format, format_clear, format-fail, ftp-write, guest, imap, land, load_clear, loadmodule, multihop, perl_clear, perlmagic, phf, rootkit, spy, syslog, teardrop, warez, warezclient, warezmaster, pod, back, ip- sweep, neptune, nmap, portsweep, satan, smurf and normal*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Categories of class attribute **\n",
    "\n",
    "\n",
    "class_attack |Category\n",
    "-------|--------------\n",
    "smurf| dos\n",
    "neptune| dos\n",
    "back| dos\n",
    "teardrop| dos\n",
    "pod| dos\n",
    "land| dos\n",
    "normal|normal\n",
    "satan|probe\n",
    "ipsweep|probe\n",
    "portsweep|probe\n",
    "nmap|probe\n",
    "warezclient|r2l\n",
    "guess_passwd|r2l\n",
    "warezmaster|r2l\n",
    "imap|r2l\n",
    "ftp_write|r2l\n",
    "multihop|r2l\n",
    "phf|r2l\n",
    "spy|r2l\n",
    "buffer_overflow|u2r\n",
    "rootkit|u2r\n",
    "loadmodule|u2r\n",
    "perl|u2r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFileConn = sc.textFile('./data/KDD/KDDTrain+.txt', 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the schema\n",
    "\n",
    "#we define the name of the columns\n",
    "\n",
    "columnNames=[\"class_attack\", \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "                 \"wrong_fragment\",\"urgent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fields initialitation all for FloatType\n",
    "connFields = [StructField(colName, FloatType(), True) for colName in columnNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we proceed to modify the respective fields so that they reflect the correct data type:\n",
    "connFields[0].dataType = StringType()\n",
    "connFields[2].dataType = StringType()\n",
    "connFields[3].dataType = StringType()\n",
    "connFields[4].dataType = StringType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can construct our schema, which we will use later below for building the data frame\n",
    "connSchema = StructType(connFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the file\n",
    "def parseReg(p):\n",
    "    return ( p[41]\n",
    "            ,float(p[0])\n",
    "            ,p[1], p[2], p[3] \n",
    "            ,float(p[4])\n",
    "            ,float(p[5])\n",
    "            ,float(p[6])\n",
    "            ,float(p[7])\n",
    "            ,float(p[8])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connParsedFile = (textFileConn.map(lambda line: line.split(','))\n",
    "                              .map(parseReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to build our data frame, using the connParsedFile RDD computed above and the schema \n",
    "# variable already calculated:\n",
    "conn = sqlContext.createDataFrame(connParsedFile, connSchema)\n",
    "conn.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the distint values of class_attack\n",
    "conn.select(\"class_attack\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeCategorical(df, catName):\n",
    "    #Encode the categorical variable in different columns foreach categories \n",
    "    #and the value is equal to 1 if the category is equal to column name and 0 otherwise. \n",
    "    #Finally drops the categorical variable\n",
    "    \n",
    "    categories = df.select(catName).distinct().toPandas()[catName]\n",
    "    aux = df\n",
    "    for c in categories:\n",
    "        aux = aux.withColumn(c, F.when(df[catName] == c, 1).otherwise(0))\n",
    "        \n",
    "    return aux.drop(catName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding *protocol_type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.select(\"protocol_type\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded = encodeCategorical(conn, \"protocol_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding *service*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.select(\"service\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded = encodeCategorical(connEncoded, \"service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding *flag*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.select(\"flag\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded = encodeCategorical(connEncoded, \"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connEncoded.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Encoding *class_attack* (**label**) like Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.select(\"class_attack\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = connEncoded.select(\"class_attack\").distinct().toPandas()[\"class_attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictCategories = dict((v,int(k)) for (k,v) in categories.to_dict().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoriesToInt(cat):\n",
    "    return dictCategories[cat]\n",
    "\n",
    "udfCategoriesToInt = udf(categoriesToInt, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connEncoded = connEncoded.withColumn(\"class_attack\", udfCategoriesToInt(\"class_attack\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Input Normalization\n",
    "\n",
    "http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connEncoded.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = connEncoded.drop(\"class_attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = features.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minValue = np.array(stats[stats.summary==\"min\"].values[0][1:], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxValue = np.array(stats[stats.summary==\"max\"].values[0][1:], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxScaler(minV, maxV, row):\n",
    "    return DenseVector([(row[i]-minV[i])/(maxV[i]-minV[i]) for i in range(len(row))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledData = connEncoded.rdd.map(lambda x: (x[0], minMaxScaler(minValue, maxValue, x[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDataFrame = sqlContext.createDataFrame(labeledData, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDataFrame.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = labeledDataFrame.limit(1).toPandas()[\"features\"].values[0]\n",
    "n_features = len(v.array)\n",
    "print(\"Total number of features: %d\" %n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateCovariance(df):\n",
    "    \"\"\"Compute the covariance matrix for a given dataframe.\n",
    "\n",
    "    Note:\n",
    "        The multi-dimensional covariance array should be calculated using outer products.  Don't\n",
    "        forget to normalize the data by first subtracting the mean.\n",
    "\n",
    "    Args:\n",
    "        df:  A Spark dataframe with a column named 'features', which (column) consists of DenseVectors.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A multi-dimensional array where the number of rows and columns both equal the\n",
    "            length of the arrays in the input dataframe.\n",
    "    \"\"\"\n",
    "    m = df.select(df['features']).rdd.map(lambda x: x[0]).mean()\n",
    "    dfZeroMean = df.select(df['features']).rdd.map(lambda x:   x[0]).map(lambda x: x-m)  # subtract the mean\n",
    "\n",
    "    return dfZeroMean.map(lambda x: np.outer(x,x)).sum()/df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eigh\n",
    "\n",
    "def pca(df, k=2):\n",
    "    \"\"\"Computes the top `k` principal components, corresponding scores, and all eigenvalues.\n",
    "\n",
    "    Note:\n",
    "        All eigenvalues should be returned in sorted order (largest to smallest). `eigh` returns\n",
    "        each eigenvectors as a column.  This function should also return eigenvectors as columns.\n",
    "\n",
    "    Args:\n",
    "        df: A Spark dataframe with a 'features' column, which (column) consists of DenseVectors.\n",
    "        k (int): The number of principal components to return.\n",
    "\n",
    "    Returns:\n",
    "        tuple of (np.ndarray, RDD of np.ndarray, np.ndarray): A tuple of (eigenvectors, `RDD` of\n",
    "        scores, eigenvalues).  Eigenvectors is a multi-dimensional array where the number of\n",
    "        rows equals the length of the arrays in the input `RDD` and the number of columns equals\n",
    "        `k`.  The `RDD` of scores has the same number of rows as `data` and consists of arrays\n",
    "        of length `k`.  Eigenvalues is an array of length d (the number of features).\n",
    "     \"\"\"\n",
    "    cov = estimateCovariance(df)\n",
    "    col = cov.shape[1]\n",
    "    eigVals, eigVecs = eigh(cov)\n",
    "    inds = np.argsort(eigVals)\n",
    "    eigVecs = eigVecs.T[inds[-1:-(col+1):-1]]  \n",
    "    components = eigVecs[0:k]\n",
    "    eigVals = eigVals[inds[-1:-(col+1):-1]]  # sort eigenvals\n",
    "    score = df.select(df['features']).rdd.map(lambda x: x[0]).map(lambda x: np.dot(x, components.T) )\n",
    "    # Return the `k` principal components, `k` scores, and all eigenvalues\n",
    "\n",
    "    return components.T, score, eigVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comp, score, eigVals = pca(labeledDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "varianceExplained = eigVals.cumsum()/eigVals.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianceExplained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1 - varianceExplained, drawstyle = 'steps-post')\n",
    "plt.title('PCA Reconstruction Error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = ((1 - varianceExplained) > 0.10).sum()\n",
    "print(\"Number of factors with 10% of reonstraction Error: \", n_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Apache Spark Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apache Spark API\n",
    "pca = PCA(k = n_factors, inputCol=\"features\", outputCol=\"pca_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcaModel = pca.fit(labeledDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataFrame = pcaModel.transform(labeledDataFrame).drop(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataFrame.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Preparation to Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling with replacement with the 30% of data\n",
    "connSample = pcaDataFrame.sample(withReplacement = True, fraction = 0.30).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Modify class_attack catagory to binary category \n",
    "connLR = connSample.withColumn('label', when(connSample['label'] == 4, 0.0).otherwise(1.0))\n",
    "connLR.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingDataLR, testDataLR) = connLR.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"pca_features\", labelCol= \"label\",\n",
    "                        maxIter = 5, regParam = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model with trainingData.\n",
    "lrModel = lr.fit(trainingDataLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression coefficients:\" , lrModel.coefficients)\n",
    "print(\"Logistic Regression intercept:\", lrModel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with testData.\n",
    "predictionsLR = lrModel.transform(testDataLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "predictionsLR.select(\"label\", \"prediction\", \"probability\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute raw scores on the test set\n",
    "predictionAndLabelsLR = predictionsLR.select(\"prediction\", \"label\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Basic Metrics object\n",
    "basicMetricsLR = MulticlassMetrics(predictionAndLabelsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Stats\")\n",
    "print(\"Weighted Precision = %s\" % basicMetricsLR.weightedPrecision)\n",
    "print(\"Weigthed Recall = %s\" % basicMetricsLR.weightedRecall)\n",
    "print(\"Weighted F1 Score = %s\" % basicMetricsLR.weightedFMeasure())\n",
    "print(\"Confusion Matrix:\")\n",
    "pd.DataFrame(basicMetricsLR.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Advanced Metrics object\n",
    "advMetricsLR = BinaryClassificationMetrics(predictionAndLabelsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % advMetricsLR.areaUnderPR)\n",
    "\n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % advMetricsLR.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.3 Model selection via Cross Validation to LogisticRegresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"pca_features\", labelCol= \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder().addGrid(lr.regParam, np.power(10.0, range(-3, 4, 1))) \\\n",
    "                         .addGrid(lr.maxIter, range(5, 21, 5)) \\\n",
    "                         .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "cvModel = cv.fit(connLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluator.evaluate(cvModel.transform(connLR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Data Preparation to SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling with replacement with the 30% of data\n",
    "connSample = pcaDataFrame.sample(withReplacement = True, fraction = 0.30).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connSample.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify class_attack catagory to binary category \n",
    "connSVN = connSample.withColumn('label', when(connSample['label'] == 4, 0.0).otherwise(1.0))\\\n",
    "          .rdd.map(lambda row: LabeledPoint(row[0], row[1:]))\n",
    "connSVN.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Training SVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingDataSVM, testDataSVM) = connSVN.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "svm = SVMWithSGD.train(trainingDataSVM, iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPredsSVM = testDataSVM.map(lambda p: Row(prediction = 1.0*svm.predict(p.features), label = p.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErr = labelsAndPredsSVM.filter(lambda r: r.label != r.prediction).count() / float(testDataSVM.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Basic Metrics object\n",
    "basicMetricsSVM =  MulticlassMetrics(labelsAndPredsSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Stats\")\n",
    "print(\"Weighted Precision = %s\" % basicMetricsSVM.weightedPrecision)\n",
    "print(\"Weighted Recall = %s\" % basicMetricsSVM.weightedRecall)\n",
    "print(\"Weighted F1 Score = %s\" % basicMetricsSVM.weightedFMeasure())\n",
    "print(\"Confusion Matrix:\")\n",
    "pd.DataFrame(basicMetricsSVM.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
